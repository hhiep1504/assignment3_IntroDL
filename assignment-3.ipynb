{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"},{"sourceId":6983304,"sourceType":"datasetVersion","datasetId":4002781}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"_uuid":"0c1a167e-8d3e-4709-bcaa-8bb04764a1ee","_cell_guid":"1c232714-7584-4b28-9a43-ffd2532e12a4","collapsed":false,"execution":{"iopub.status.busy":"2023-11-16T17:13:57.834597Z","iopub.execute_input":"2023-11-16T17:13:57.834962Z","iopub.status.idle":"2023-11-16T17:14:22.702435Z","shell.execute_reply.started":"2023-11-16T17:13:57.834933Z","shell.execute_reply":"2023-11-16T17:14:22.700891Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"_uuid":"fec017da-b857-492e-89ad-518ca0885242","_cell_guid":"c0e2d3f0-411a-4b4c-998d-1c912dcd89b1","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:07:32.309430Z","iopub.execute_input":"2023-11-17T02:07:32.309751Z","iopub.status.idle":"2023-11-17T02:07:52.823884Z","shell.execute_reply.started":"2023-11-17T02:07:32.309725Z","shell.execute_reply":"2023-11-17T02:07:52.822931Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom torchvision.transforms import ToTensor\nfrom PIL import Image\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision \nfrom torchvision import transforms\nfrom torchinfo import summary\nimport timm\nimport segmentation_models_pytorch as smp\nimport wandb","metadata":{"_uuid":"551b89f2-c7fb-44c4-9247-0c7e24510ea4","_cell_guid":"7feafd6b-c3cd-4939-b9b6-94edf1dd8c62","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:21.238418Z","iopub.execute_input":"2023-11-17T02:08:21.238768Z","iopub.status.idle":"2023-11-17T02:08:23.332269Z","shell.execute_reply.started":"2023-11-17T02:08:21.238740Z","shell.execute_reply":"2023-11-17T02:08:23.331380Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"_uuid":"bacfcca1-6ca5-4ece-a3aa-218504ba4965","_cell_guid":"98d96693-bcb2-4e1d-a672-65502489fbeb","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:27.193302Z","iopub.execute_input":"2023-11-17T02:08:27.194199Z","iopub.status.idle":"2023-11-17T02:08:28.206596Z","shell.execute_reply.started":"2023-11-17T02:08:27.194165Z","shell.execute_reply":"2023-11-17T02:08:28.205546Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"_uuid":"5d2b9aec-1916-4c94-beec-43ad3297ea7d","_cell_guid":"34cda2d6-208a-4964-8cc0-9dca7cd5cc3b","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:29.999834Z","iopub.execute_input":"2023-11-17T02:08:30.000264Z","iopub.status.idle":"2023-11-17T02:08:30.078868Z","shell.execute_reply.started":"2023-11-17T02:08:30.000226Z","shell.execute_reply":"2023-11-17T02:08:30.077765Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetCustom(Dataset):\n    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.resize = resize\n        self.transform = transform\n        self.images = os.listdir(self.img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    \n    def read_mask(self, mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.resize(image, self.resize)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n        lower_red1 = np.array([0, 100, 20])\n        upper_red1 = np.array([10, 255, 255])\n        lower_red2 = np.array([160,100,20])\n        upper_red2 = np.array([179,255,255])\n        \n        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n        \n        red_mask = lower_mask_red + upper_mask_red\n        red_mask[red_mask != 0] = 1\n\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n\n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = np.expand_dims(full_mask, axis=-1) \n        full_mask = full_mask.astype(np.uint8)\n        \n        return full_mask\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        label_path = os.path.join(self.label_dir, self.images[idx])\n        image = cv2.imread(img_path)  #  BGR\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n        label = self.read_mask(label_path)  \n        image = cv2.resize(image, self.resize)\n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"_uuid":"9ddda44a-8479-4f75-969f-db1cc98977d7","_cell_guid":"0986b82a-ed00-4eac-b6f3-18be175c20c1","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:33.782629Z","iopub.execute_input":"2023-11-17T02:08:33.783480Z","iopub.status.idle":"2023-11-17T02:08:33.796352Z","shell.execute_reply.started":"2023-11-17T02:08:33.783447Z","shell.execute_reply":"2023-11-17T02:08:33.795227Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nimage_path = []\nTRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\nfor root, dirs, files in os.walk(TRAIN_DIR):\n    for file in files:\n        path = os.path.join(root,file)\n        image_path.append(path)\n        \nlen(image_path)","metadata":{"_uuid":"6716fa77-01d7-4184-aa02-51659795b00d","_cell_guid":"7faa329e-57db-4e1c-b5c5-315ca7b8bbfe","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:36.701706Z","iopub.execute_input":"2023-11-17T02:08:36.702381Z","iopub.status.idle":"2023-11-17T02:08:37.051479Z","shell.execute_reply.started":"2023-11-17T02:08:36.702346Z","shell.execute_reply":"2023-11-17T02:08:37.050534Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_path = []\nTRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\nfor root, dirs, files in os.walk(TRAIN_MASK_DIR):\n    for file in files:\n        path = os.path.join(root,file)\n        mask_path.append(path)\n        \nlen(mask_path)","metadata":{"_uuid":"2ca03d62-2849-4104-bf78-f0cffff43ae3","_cell_guid":"85bdae30-f5cc-42af-9911-fbc560cc3935","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:39.539480Z","iopub.execute_input":"2023-11-17T02:08:39.539810Z","iopub.status.idle":"2023-11-17T02:08:39.940105Z","shell.execute_reply.started":"2023-11-17T02:08:39.539786Z","shell.execute_reply":"2023-11-17T02:08:39.939063Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetCustom(img_dir= TRAIN_DIR,\n                             label_dir= TRAIN_MASK_DIR,\n                             resize= (256,256),\n                             transform = None)","metadata":{"_uuid":"41a13000-90ed-4417-87b1-204f3de77c06","_cell_guid":"99543edf-d4f2-4470-a9dd-0331dbc574b6","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:41.850999Z","iopub.execute_input":"2023-11-17T02:08:41.851714Z","iopub.status.idle":"2023-11-17T02:08:41.858584Z","shell.execute_reply.started":"2023-11-17T02:08:41.851679Z","shell.execute_reply":"2023-11-17T02:08:41.857701Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nimages_data = []\nlabels_data = []\nfor x,y in dataset:\n    images_data.append(x)\n    labels_data.append(y)","metadata":{"_uuid":"df34009b-38f9-4f8b-93ef-bbd86dff5510","_cell_guid":"4116103e-adfb-4c8e-830a-f5be0566de25","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:08:44.290023Z","iopub.execute_input":"2023-11-17T02:08:44.290762Z","iopub.status.idle":"2023-11-17T02:09:21.559326Z","shell.execute_reply.started":"2023-11-17T02:08:44.290728Z","shell.execute_reply":"2023-11-17T02:09:21.558425Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"resnet34\",        \n    encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)","metadata":{"_uuid":"673369f5-84f3-4e14-a346-93a115e42912","_cell_guid":"cb804202-9736-4960-b045-70229a3c0dd3","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:09:30.159176Z","iopub.execute_input":"2023-11-17T02:09:30.160107Z","iopub.status.idle":"2023-11-17T02:09:30.832873Z","shell.execute_reply.started":"2023-11-17T02:09:30.160067Z","shell.execute_reply":"2023-11-17T02:09:30.831889Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, targets, transform=None):\n        self.data = data\n        self.targets = targets\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image = self.data[index]\n        label = self.targets[index]\n        assert image.shape[:2] == label.shape[:2]\n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image'].float()\n            label = transformed['mask'].float()\n            label = label.permute(2, 0, 1)\n        return image, label\n    \n    def __len__(self):\n        return len(self.data)","metadata":{"_uuid":"3be43ef7-b918-4ea4-9389-c05b8c59d8df","_cell_guid":"45e3813a-0a3a-4aba-a36e-ef0c0d9313ee","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:09:45.084564Z","iopub.execute_input":"2023-11-17T02:09:45.085235Z","iopub.status.idle":"2023-11-17T02:09:45.092741Z","shell.execute_reply.started":"2023-11-17T02:09:45.085201Z","shell.execute_reply":"2023-11-17T02:09:45.091773Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transformation = A.Compose([\n    A.HorizontalFlip(p=0.4),\n    A.VerticalFlip(p=0.4),\n    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\nval_transformation = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])","metadata":{"_uuid":"7cd207bd-2483-4cdb-a15a-dd7980a2325a","_cell_guid":"9504f839-cf94-4062-bde4-205f52c6b74d","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:09:51.594364Z","iopub.execute_input":"2023-11-17T02:09:51.594752Z","iopub.status.idle":"2023-11-17T02:09:51.603421Z","shell.execute_reply.started":"2023-11-17T02:09:51.594721Z","shell.execute_reply":"2023-11-17T02:09:51.602243Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * len(images_data))\nval_size = len(images_data) - train_size\ntrain_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transformation)\nval_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transformation)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)","metadata":{"_uuid":"938941c1-8d7d-4aa7-9324-0cd7dd666a05","_cell_guid":"623e4642-2b07-4e64-8814-b7c5476ebce2","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:09:53.733228Z","iopub.execute_input":"2023-11-17T02:09:53.733959Z","iopub.status.idle":"2023-11-17T02:09:53.740729Z","shell.execute_reply.started":"2023-11-17T02:09:53.733928Z","shell.execute_reply":"2023-11-17T02:09:53.739448Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0001\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"_uuid":"71abd15e-5ae7-4e20-ad1f-ff9284ca9241","_cell_guid":"d3f84ace-dab9-4fc6-8d71-8b684ee6e5d1","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:09:55.912614Z","iopub.execute_input":"2023-11-17T02:09:55.912969Z","iopub.status.idle":"2023-11-17T02:09:55.919074Z","shell.execute_reply.started":"2023-11-17T02:09:55.912939Z","shell.execute_reply":"2023-11-17T02:09:55.918079Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_dict= {0: (0, 0, 0),\n             1: (255, 0, 0),\n             2: (0, 255, 0)}\ndef mask_to_rgb(mask, color_dict):\n    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n\n    for k in color_dict.keys():\n        output[mask==k] = color_dict[k]\n\n    return np.uint8(output)","metadata":{"_uuid":"e4f7ef28-7c3b-4f06-9482-b692194f5d54","_cell_guid":"ed8c62d0-8691-4860-b64e-38f92c680c3d","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:09:57.558012Z","iopub.execute_input":"2023-11-17T02:09:57.558467Z","iopub.status.idle":"2023-11-17T02:09:57.565142Z","shell.execute_reply.started":"2023-11-17T02:09:57.558386Z","shell.execute_reply":"2023-11-17T02:09:57.564044Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(\n    # set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"fce1a1d66b4e11a4dfb138a721a7f283a942ae4a\",\n)\nwandb.init(\n    project = \"PolypSegment\"\n)","metadata":{"_uuid":"e02921d9-3e08-4435-a995-b3381812c6ae","_cell_guid":"3cec8a4b-7c3d-47e0-ba3a-4f6b15d25a10","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:11:17.489991Z","iopub.execute_input":"2023-11-17T02:11:17.490395Z","iopub.status.idle":"2023-11-17T02:11:48.797232Z","shell.execute_reply.started":"2023-11-17T02:11:17.490362Z","shell.execute_reply":"2023-11-17T02:11:48.795966Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tqdm","metadata":{"_uuid":"e8044373-7808-4782-a684-c0ad94dc3cc2","_cell_guid":"b7a30fd0-fe85-49c8-b166-005ec296391d","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:13:07.363347Z","iopub.execute_input":"2023-11-17T02:13:07.363707Z","iopub.status.idle":"2023-11-17T02:13:19.424202Z","shell.execute_reply.started":"2023-11-17T02:13:07.363676Z","shell.execute_reply":"2023-11-17T02:13:19.423075Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\nnum_epochs = 250\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\nbest_val_loss = 999\n\nepoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        labels = labels.squeeze(dim=1).long()\n        outputs = model(images)\n    \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        train_loss += loss.item()\n    model.eval()\n    with torch.no_grad():\n        val_loss = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            labels = labels.squeeze(dim=1).long()\n            \n            outputs = model(images)\n\n            val_loss += criterion(outputs.float(),labels.long()).item()\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        checkpoint = { \n            'epoch': epoch,\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'loss': val_loss,\n        }\n        save_path = f'model.pth'\n        torch.save(checkpoint, save_path)\n        \n    epoch_bar.update(1)\n    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader)})\nepoch_bar.close()","metadata":{"_uuid":"333b03d0-a48f-40e1-8d95-f1e5a874a663","_cell_guid":"2184a3ef-2009-4b92-915e-3e6a35c2d0a3","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T02:23:56.776775Z","iopub.execute_input":"2023-11-17T02:23:56.777569Z","iopub.status.idle":"2023-11-17T04:20:45.420171Z","shell.execute_reply.started":"2023-11-17T02:23:56.777537Z","shell.execute_reply":"2023-11-17T04:20:45.419297Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/unet-model/model.pth')\nmodel.load_state_dict(checkpoint['model'])\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"_uuid":"0bde0b3a-bd81-4172-82b3-bc7c3c766cb8","_cell_guid":"cd15e7a8-04df-4051-8aec-2b77ffb36067","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T04:21:11.146960Z","iopub.execute_input":"2023-11-17T04:21:11.147434Z","iopub.status.idle":"2023-11-17T04:21:13.955080Z","shell.execute_reply.started":"2023-11-17T04:21:11.147395Z","shell.execute_reply":"2023-11-17T04:21:13.954153Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir prediction","metadata":{"_uuid":"5c6add0f-f0a6-4da8-abc2-01bef31eb01f","_cell_guid":"9ff8db99-e663-4fb2-8af7-30fb303e2ce2","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T04:21:19.143859Z","iopub.execute_input":"2023-11-17T04:21:19.144716Z","iopub.status.idle":"2023-11-17T04:21:20.187100Z","shell.execute_reply.started":"2023-11-17T04:21:19.144680Z","shell.execute_reply":"2023-11-17T04:21:20.185801Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nfor i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n    ori_img = cv2.imread(img_path)\n    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n    ori_w = ori_img.shape[0]\n    ori_h = ori_img.shape[1]\n    img = cv2.resize(ori_img, (256, 256))\n    transformed = val_transformation(image=img)\n    input_img = transformed[\"image\"]\n    input_img = input_img.unsqueeze(0).to(device)\n    with torch.no_grad():\n        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n    mask = cv2.resize(output_mask, (ori_h, ori_w))\n    mask = np.argmax(mask, axis=2)\n    mask_rgb = mask_to_rgb(mask, color_dict)\n    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb)","metadata":{"_uuid":"fb78dd81-d8eb-43e1-b808-875caceaf162","_cell_guid":"888b0c08-e5bc-45c1-bb2f-dac30364ca6e","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T04:21:22.271937Z","iopub.execute_input":"2023-11-17T04:21:22.272920Z","iopub.status.idle":"2023-11-17T04:21:48.873883Z","shell.execute_reply.started":"2023-11-17T04:21:22.272884Z","shell.execute_reply":"2023-11-17T04:21:48.873055Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 225] = 255\n    pixels[pixels <= 225] = 0\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    \n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/prediction'\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"_uuid":"1713520d-c2fc-44ec-9bb8-6f6ef2d2c67f","_cell_guid":"87dabe32-f68e-4ae3-b446-a4b66f5d3c4c","collapsed":false,"execution":{"iopub.status.busy":"2023-11-17T04:21:54.066335Z","iopub.execute_input":"2023-11-17T04:21:54.067156Z","iopub.status.idle":"2023-11-17T04:21:57.357665Z","shell.execute_reply.started":"2023-11-17T04:21:54.067121Z","shell.execute_reply":"2023-11-17T04:21:57.356658Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Infer**","metadata":{"_uuid":"feae40dd-833d-41c8-9e56-232bea6ef1df","_cell_guid":"e7bea300-b456-460a-a2c6-04972094d722","trusted":true}},{"cell_type":"code","source":"# from torch.jit import load\n# model = UNet()\n# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n\n# checkpoint = torch.load(pretrained_path)","metadata":{"_uuid":"76427aff-4473-464b-905b-9f6545289f05","_cell_guid":"735efed6-ccc1-4040-9c67-62e12c5acff4","collapsed":false,"execution":{"iopub.status.busy":"2023-11-08T06:55:28.381375Z","iopub.execute_input":"2023-11-08T06:55:28.382136Z","iopub.status.idle":"2023-11-08T06:55:28.940632Z","shell.execute_reply.started":"2023-11-08T06:55:28.382101Z","shell.execute_reply":"2023-11-08T06:55:28.939793Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer.load_state_dict(checkpoint['optimizer'])","metadata":{"_uuid":"05d24e94-9cc6-456b-a2c4-8ddf6f5a2b60","_cell_guid":"85668e2c-a3a9-49db-b80b-8844f5089885","collapsed":false,"execution":{"iopub.status.busy":"2023-11-08T06:57:55.245294Z","iopub.execute_input":"2023-11-08T06:57:55.245656Z","iopub.status.idle":"2023-11-08T06:57:55.423820Z","shell.execute_reply.started":"2023-11-08T06:57:55.245628Z","shell.execute_reply":"2023-11-08T06:57:55.422815Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import OrderedDict\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# # load params\n# model.load_state_dict(new_state_dict)","metadata":{"_uuid":"ce13ab39-454d-4354-8545-95d1abb6f869","_cell_guid":"b8d8e33b-b2bc-453c-a457-57295043c397","collapsed":false,"execution":{"iopub.status.busy":"2023-11-08T07:05:00.457056Z","iopub.execute_input":"2023-11-08T07:05:00.457967Z","iopub.status.idle":"2023-11-08T07:05:00.501755Z","shell.execute_reply.started":"2023-11-08T07:05:00.457935Z","shell.execute_reply":"2023-11-08T07:05:00.500785Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}